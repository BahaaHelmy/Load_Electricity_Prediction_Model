{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "cde45a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "7c156724",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the data file\n",
    "data=pd.read_csv('assignment-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "00e2358d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>datetime</th>\n",
       "      <th>load</th>\n",
       "      <th>apparent_temperature</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>dew_point</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>803.22270</td>\n",
       "      <td>10.45800</td>\n",
       "      <td>10.45800</td>\n",
       "      <td>0.955500</td>\n",
       "      <td>8.946000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01 00:15:00</td>\n",
       "      <td>774.89523</td>\n",
       "      <td>10.32675</td>\n",
       "      <td>10.32675</td>\n",
       "      <td>0.961625</td>\n",
       "      <td>8.911875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-01 00:30:00</td>\n",
       "      <td>731.46927</td>\n",
       "      <td>10.19550</td>\n",
       "      <td>10.19550</td>\n",
       "      <td>0.967750</td>\n",
       "      <td>8.877750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-01-01 00:45:00</td>\n",
       "      <td>713.93870</td>\n",
       "      <td>10.06425</td>\n",
       "      <td>10.06425</td>\n",
       "      <td>0.973875</td>\n",
       "      <td>8.843625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>699.23007</td>\n",
       "      <td>9.93300</td>\n",
       "      <td>9.93300</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>8.809500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             datetime       load  apparent_temperature  \\\n",
       "0           0  2018-01-01 00:00:00  803.22270              10.45800   \n",
       "1           1  2018-01-01 00:15:00  774.89523              10.32675   \n",
       "2           2  2018-01-01 00:30:00  731.46927              10.19550   \n",
       "3           3  2018-01-01 00:45:00  713.93870              10.06425   \n",
       "4           4  2018-01-01 01:00:00  699.23007               9.93300   \n",
       "\n",
       "   temperature  humidity  dew_point  wind_speed  cloud_cover        date  \n",
       "0     10.45800  0.955500   8.946000         0.0          0.0  2018-01-01  \n",
       "1     10.32675  0.961625   8.911875         0.0          0.0  2018-01-01  \n",
       "2     10.19550  0.967750   8.877750         0.0          0.0  2018-01-01  \n",
       "3     10.06425  0.973875   8.843625         0.0          0.0  2018-01-01  \n",
       "4      9.93300  0.980000   8.809500         0.0          0.0  2018-01-01  "
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Return the first 5 rows of data\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "5845911b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the date column is in datetime format\n",
    "data['datetime']=pd.to_datetime(data['datetime'],format= \"%Y-%m-%d %H:%M:%S\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "766a75e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-275-93e0aa8de5b6>:7: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  data['week']=data['datetime'].dt.week\n",
      "<ipython-input-275-93e0aa8de5b6>:8: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  data['weekofyear']=data['datetime'].dt.weekofyear\n"
     ]
    }
   ],
   "source": [
    "#Refine the datetime attribute to increase the accurecy of the model\n",
    "data['year']=data['datetime'].dt.year\n",
    "data['month']=data['datetime'].dt.month\n",
    "data['day']=data['datetime'].dt.day\n",
    "data['hour']=data['datetime'].dt.hour\n",
    "data['minutes']=data['datetime'].dt.minute\n",
    "data['week']=data['datetime'].dt.week\n",
    "data['weekofyear']=data['datetime'].dt.weekofyear\n",
    "data['dayofweek']=data['datetime'].dt.dayofweek\n",
    "data['weekday']=data['datetime'].dt.weekday\n",
    "data['quarter']=data['datetime'].dt.quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "a27be5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 2-> Nan values filtering\n",
    "Nan_Val=data['load'].isna()\n",
    "nan_pred=data.loc[Nan_Val]\n",
    "X_Nan_Pred=nan_pred[['apparent_temperature','temperature','humidity','dew_point','wind_speed','cloud_cover','month','day','hour','minutes','week','weekofyear','dayofweek','weekday','quarter']]\n",
    "y_Nan_Pred=nan_pred[['load']]\n",
    "X_Nan_Pred=pd.DataFrame(X_Nan_Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06cfab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiOutputRegressor(estimator=GradientBoostingRegressor())\n"
     ]
    }
   ],
   "source": [
    "data.dropna(inplace=True)\n",
    "X=data[['apparent_temperature','temperature','humidity','dew_point','wind_speed','cloud_cover','month','day','hour','minutes','week','weekofyear','dayofweek','weekday','quarter']]\n",
    "y=data[['load']]\n",
    "gbr = GradientBoostingRegressor()\n",
    "model = MultiOutputRegressor(estimator=gbr)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3,random_state=500) # 70% training and 30% test\n",
    "print(model)\n",
    "model.fit(X_train, y_train)\n",
    "train_score=(model.score(X_train, y_train))\n",
    "print(\"Model training accurecy is: \",train_score*100,'%')\n",
    "yhat = model.predict(X_test)\n",
    "ynan = model.predict(X_Nan_Pred)\n",
    "nan_pred=pd.DataFrame(nan_pred)\n",
    "df=pd.DataFrame()\n",
    "df['datetime']=nan_pred['datetime']\n",
    "df['forecast']= np.array(ynan)\n",
    "#Task 1 - Do a short term forecast for the day 14 December 2020 in the frequency of 15 minutes.\n",
    "New_Test_Data=[[10.45800,10.45800,0.955500,8.946000,0.0,0.0,12,14,0.0,15,2,1,4,1,4]]\n",
    "x={'datetime':\"2020-12-14 00:15:00\",'forecast':model.predict(New_Test_Data)[0][0]}\n",
    "df=df.append(x, ignore_index = True)\n",
    "df.to_csv('Output_Load_forecasting.csv',index=False)\n",
    "test_score=(model.score(X_test,yhat))\n",
    "print(\"Model test accurecy is: \",(model.score(X_test,yhat))*100,'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1729fcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Draw a scatter plot while assigning point colors and sizes to different\n",
    "# variables in the dataset\n",
    "f, ax = plt.subplots(figsize=(6.5, 6.5))\n",
    "sns.despine(f, left=True, bottom=True)\n",
    "clarity_ranking = [\"I1\", \"SI2\", \"SI1\", \"VS2\", \"VS1\", \"VVS2\", \"VVS1\", \"IF\"]\n",
    "sns.scatterplot(x=\"datetime\", y=\"load\",\n",
    "                hue=\"month\", size=\"year\",\n",
    "                palette=\"ch:r=-.2,d=.3_r\",\n",
    "                hue_order=clarity_ranking,\n",
    "                sizes=(1, 10), linewidth=0,\n",
    "                data=data, ax=ax)\n",
    "plt.savefig('d2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065842f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "# Plot miles per gallon against horsepower with other semantics\n",
    "sns.relplot(x=\"datetime\", y=\"load\", hue=\"year\", size=\"month\",\n",
    "            sizes=(40, 400), alpha=.5, palette=\"muted\",\n",
    "            height=10, data=data)\n",
    "plt.savefig('books_read.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "79f3c2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]] [[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_range = np.arange(1, 250, 2)\n",
    "\n",
    "train_scores, test_scores = validation_curve(MultiOutputRegressor(),X, y, param_name=\"estimator\", param_range=param_range,cv=4, scoring=\"accuracy\", n_jobs=-1)\n",
    "\n",
    "train_score, test_score = validation_curve(KNeighborsClassifier(), X, y,\n",
    "                                       param_name = \"n_neighbors\",\n",
    "                                       param_range = parameter_range,\n",
    "                                        cv = 5, scoring = \"accuracy\")\n",
    "\n",
    "#train_score=np.argmax(train_score, axis=1)\n",
    "#test_score=np.argmax(test_score, axis=1)\n",
    "train_mean = np.mean(train_score, axis=0)\n",
    "train_std = np.std(train_score, axis=0)\n",
    "test_mean = np.mean(test_score, axis=1)\n",
    "test_std = np.std(test_score, axis=1)\n",
    "\n",
    "plt.subplots(1, figsize=(7,7))\n",
    "plt.plot(param_range, train_mean, label=\"Training score\", color=\"black\")\n",
    "plt.plot(param_range, test_mean, label=\"Cross-validation score\", color=\"dimgrey\")\n",
    "\n",
    "plt.fill_between(param_range, train_mean - train_std, train_mean + train_std, color=\"gray\")\n",
    "plt.fill_between(param_range, test_mean - test_std, test_mean + test_std, color=\"gainsboro\")\n",
    " \n",
    "plt.title(\"Validation Curve With Random Forest\")\n",
    "plt.xlabel(\"Number Of Trees\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9ee6ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
